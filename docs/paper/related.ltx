\section{Related Work}
	\label{Sec:related}

\subsection{Extensions to Pattern Matching}

	In this section we take a closer look at the choice operator,
	and its impact on programming in RhoStratego.  It is well
	known that conventional pattern matching is not perfect
	\cite{firstclasspatterns, patternguards}.  It turns out that
	the choice operator eliminates the need for many of the
	proposals to extend pattern matching in functional languages
	such as Haskell, including {\em views}, {\em pattern guards},
	{\em transformational patterns}, and {\em first-class
	patterns}.  Furthermore, it makes \code{case}-expressions and
	sugar such as Haskell's `equational style' unnecessary.

\paragraph{Case Expressions}

	Case expressions, present in most functional languages, are
	unnecessary in the presence of the choice operator, and
	consequently they do not exist in Rho\-Stratego.  After all,
	the following Haskell-like construct
\begin{verbatim}
  f = x -> case x of
             A       -> 123;
             B "foo" -> 456;
             y       -> 0;
\end{verbatim}
	can easily be written in RhoStratego as a set of choices.  In
	fact, the choice alternatives are first-class and can be
	defined separately:
\begin{verbatim}
  a = A       -> 123;
  b = B "foo" -> 456;
  c = y       -> 0;
  f = a <+ b <+ c;
\end{verbatim}
	Similarly, Haskell's equational style is unnecessary. In the
	equational style a function definition consists of a number of
	pattern-guarded equations which must be tried one after
	another. The various definitions for a function can be written
	as choice alternatives.  The resulting code is in fact shorter
	than when written in the equational style.

\paragraph{Views}

	Views \cite{views87} were proposed to address the problem that
	regular pattern matching is rather limited since we can only
	match with actual constructors.  As a consequence we cannot
	match against, e.g., the end of a list instead of the head,
	nor can we match against abstract data types since there is
	simply nothing to match against.  Using the views proposal for
	Haskell \cite{views96} we can write the following view to
	match against the end of a list:
\begin{verbatim}
  view Tsil a of [a] = Lin | Snoc y ys where
    tsil xs =
      case reverse xs of
        [] -> Lin
        (y:ys) -> Snoc y ys
\end{verbatim}
	where matching against a \code{Snoc}-constructor causes the
	function \code{tsil} to be applied to the value:
\begin{verbatim}
  f (Snoc y ys) = y
  f Lin = 0
\end{verbatim}

	It is worth pointing out why views (and transformational
	patterns) are useful.  The reason is that the equational style
	can only be used if the non-applicability of an equation can
	be discovered in the pattern.  When that is not possible, the
	equational style falls apart, and we have to explicitly write
	the traversal through the alternatives (the equations) as a
	series of ever more deeply nested \code{case}-expressions.
	The choice operator liberates us from this regime, hence the
	main motivation for views and transformational patterns
	disappears.  With the choice operator, the previous example
	becomes:
\begin{verbatim}
  f = reverse | ((y:ys) -> y <+ [] -> 0);
\end{verbatim}

	Views still have the advantage that the transformation to be
	applied (e.g., \code{tsil}) is implicit in the name of the
	patterns (e.g., \code{Snoc}), but this seems only a minor
	advantage.

\paragraph{Pattern Guards}

	In Haskell's equational notation, we can use boolean guards to
	further restrict the applicability of an equation, e.g.,
	\code{f x | x > 3 = 123} (the symbol \code{|} should not be
	confused with RhoStratego's sequential composition operator).
	However, there is a disparity between patterns and guards:
	patterns can bind variables, whereas guards cannot.  For
	example, if we want to return a variable from an environment,
	or 0 if it is undefined, we would write:
\begin{verbatim}
  f env var | isJust (lookup env var)
            = fromJust (lookup env var)
  f env var = 0
\end{verbatim}
	where \code{lookup} has type \code{[($\alpha$, $\beta$)] \ra
	$\alpha$ \ra Maybe $\beta$}.  This is awkward because we now
	inspect the result of \code{lookup} twice.  Pattern guards
	\cite{patternguards} redefine a guard as a list of qualifiers,
	just as in a list comprehension, so that binding can occur:
\begin{verbatim}
  f env var | Just x <- lookup env var = x
  f env var = 0
\end{verbatim}
 	But when we have a choice operator, we can simply write the
 	above as a choice.  In fact, we could just get rid of the
 	\code{Maybe} result of \code{lookup} altogether, making it of
 	type \code{[($\alpha$, $\beta$)] \ra $\alpha$ \ra $\beta$},
 	and arrive at:
\begin{verbatim}
  f = env -> var -> (lookup env var <+ 0);
\end{verbatim}

\paragraph{Transformational Patterns}

	Transformational patterns \cite{patternguards} provide a cheap
	alternative to views, allowing us to write the previous
	example as:
\begin{verbatim}
  f env (Just x)!(lookup env) = x
  f env var = 0
\end{verbatim}
 	Hence, transformational patterns are just view transformations
 	made explicit.  The choice operator allows a similar notation:
\begin{verbatim}
  f = env -> ((lookup env) | (Just x -> x) 
              <+ y -> 0);
\end{verbatim}

	However, it is still desirable to have some mechanism like
	views or transformational patterns, if only for reasons of
	symmetry. It is ugly if patterns can only be used to match
	against concrete data types.  For this reason Rho\-Stratego
	offers a syntactic sugar similar to, but slightly simpler
	than, transformational patterns.  The snoc-list example given
	above can be written in RhoStratego as follows:
\begin{verbatim}
  snoc = reverse | ((x:xs) -> <x, xs>);
  lin = [] -> <>;
  f = {snoc} x xs -> x <+ {lin} -> 0;
\end{verbatim}
	The angle brackets denote tuple construction.  A pattern
	\verb|{...}| with $n$ pattern arguments specifies an
	expression which is applied to the argument.  The expression
	should return a tuple of arity $n$.  The pattern arguments are
	then matched against the elements of the tuple.  Therefore,
	\code{f} is desugared into:
\begin{verbatim}
  f =  y -> (<x, xs> -> x) (snoc y) 
    <+ y -> (<>      -> 0) (lin y);
\end{verbatim}


\paragraph{First-class Patterns}

	Tullsen \cite{firstclasspatterns} treats patterns as functions
	of type \code{$\alpha$ \ra Maybe $\beta$}, and combinators are
	provided to combine basic patterns into complex ones.
	Although conceptually elegant, this approach suffers from the
	fact that the syntax is not very attractive.  Furthermore,
	every function that can fail must have the \code{Maybe} type;
	in our approach, failure is propagated implicitly.


\subsection{\rcalc{}}

	RhoStratego's name derives from its origin as an experimental
	implementation of the {\em \rcalc{}}.  The \rcalc{}, or {\em
	rewriting calculus} \cite{matchingpower} aims to integrate
	first-order rewriting, the \lcalc{}, and non-determinism.
	Although we have diverged from that goal and Rho\-Stratego has
	become a conventional functional language extended with
	first-class rules and generic traversals, it is still
	interesting to compare Rho\-Stratego to the \rcalc{}.

	The syntax of the \rcalc{} is defined as follows:
\[
t ::= var \alt constant \alt t \ra t \alt t \bullet t \alt null \alt t, t
\]
	$t \ra t$ represents abstraction, $t \bullet t$ stands for
	application, $t, t$ builds a structure, and $null$ denotes the
	empty structure.  It is easy to see that the \lcalc{} and term
	rewriting can be encoded in the \rcalc{}.  For example, $x \ra
	y \ra x$ is exactly the $\lambda$-term $\lambda x . \lambda y
	.  x$, and $(F(x) \ra x) \bullet F(A)$ is the
	rewrite rule $F(x) \ra x$ applied to the term $F(A)$.

	The principal semantic rule of the calculus is the {\sc Fire}
	rule, which is essentially a generalized form of
	$\beta$-reduction:
\[
(t_1 \ra t_2) \bullet t_3 
\goesto \left\{
\begin{array}{ll}
null & \text{if} \; \textrm{Sol}(t_1 \match_\mathbb{T} t_3) =
\emptyset  \\
\sigma_1 t_2, \dots, \sigma_n t_2 & 
\text{where} \; \sigma_i \in \textrm{Sol}(t_1 \match_\mathbb{T} t_3)
\end{array}
\right.
\]
The matching theory $\mathbb{T}$, which is a parameter of the
calculus, determines the solutions and substitutions arising out of a
match ($\textrm{Sol}(t_1 \match_\mathbb{T} t_3)$ returns the set of
substitutions).  In addition, the calculus has the {\em distribution
  rules} $(t_1, t_2) \bullet t_3 \goesto t_1 \bullet t_3, t_2 \bullet
t_3$ and $null \bullet t \goesto null$.

If we view the structure-building operator ($,$) as a choice operator
and $null$ as failure, then the distribution rules correspond to the
{\sc Distrib} and {\sc PropFunc} rules of RhoStratego.  Furthermore,
if we take as the matching theory $\mathbb{T}$ the theory of equality
modulo $\alpha$-renaming, then the {\sc Fire} rule corresponds to our
choice rules, except that there are no cuts.  A rule either succeeds
and has exactly one solution, or it fails and yields failure.
Finally, the proper choice semantics is obtained by defining
$\mathbb{T}$ such that $t_1, t_2$ is equivalent to $t_1$ if $t_1$ is
not $null$, or to $t_2$ otherwise.


\subsection{Polytypic Programming}

Generic or polytypic programming makes it possible to write functions
that operate on different data types.  For instance, functions such as
\code{termSize} can be readily defined in PolyP \cite{polyp} or using
derivable type classes \cite{derivabletypeclasses}.

However, other kinds of generic traversals are more troublesome.
Consider \code{topdown (Exp?Var "x" -> Var "y")} (i.e., rename a
variable named \code{"x"} to \code{"y"}).  We {\em can} write generic
code for this using derivable type classes, for example.  We create a
class together with a generic default method to traverse over
arbitrary data types, and declare all data types we want to traverse
over to be instances of this class, except that we write a {\em
  specific} instance for type \code{Exp} to actually perform the
renaming.

The problem with this approach is that there can be at most one class
instance declaration for each type, so if we want to define another
topdown traversal, we have to define a {\em new} class, providing
different instances for the appropriate types.  And we cannot write a
general class \code{Topdown} containing a method that is parameterized
with a function applying the transformation, since such a function
would necessarily have type $\alpha \ra \alpha$ (it must operate on
all types), i.e., we can only pass the function \code{id}.

The idea behind type-safe functional strategies
\cite{typesafefuncstrat} is similar: genericity is achieved through
the use of Haskell type classes (which may be generated automatically
using an external tool).

